Overview The Install guide covers the LiveStats install process. Its purpose is to allow users to quickly perform a new install. Users should already have prior experience with installing Linux, Apache and MySQL. LiveStats monitors sandbox servers for such things as TCP connections, traffic and database, memory and CPU usage. On each sandbox, data for such things as slow calls, resource usage, performance counters, ping times, game statistics, geographic locations, traffic and the logs is collected and and transmitted to the LiveStats server. LiveStats provides immediate statistics on every datacenter server and presents this information in a series of graphs and charts which allow dat:wa center personnel to visualize the data and see trends as and when they happen. Installation Prerequisites LiveStats Server This software package is installed on the Hosting/Hardware/LiveStats datacenter server. Software Prerequisites * Notes: o You need access to a Linux machine and the LiveStats package provided to you by Quazal. This guide assumes that you have a CentOS 5.x installation ready with root or sudo access and connected to the local network. * Username and Password: o You will give the stats username sudo access and full read/write permissions to the LiveStats installation. We recommend using this username to perform the install steps and using sudo if you need root access. * Database: o LiveStats is dependent on a MySQL database that must be installed and configured separately or on the same server depending on your needs. o The host, port number, username and password to access the database are hardcoded in the header of every Perl script in Livestats. If you choose not to use those present there, you will need to update the scripts to reflect your changes. o LiveStats can also be configured to run on master/slave instances of MySQL since the LiveStats insert scripts are very resource intensive and can bog down one instance. It is possible to set the insert scripts to execute on the master instance and run the make scripts (which look up data) on the read-only slave. This is completely optional and it depends on your needs. Instructions LiveStats Server Install Initial Setup Quazal will provide a package usually called liveltats.zip with all the files required for this setup. If this setup is internal or if you have access to it, the files are also available directly from CVS under the path /Operations/livestats/. Once extracted, your livestats directory should have the following structure: /usr/local/livestats/ /usr/local/livestats/bin /usr/local/livestats/database /usr/local/livestats/sbin /usr/local/livestats/setup /usr/local/livestats/templates /usr/local/livestats/www/internal /usr/local/livestats/www/external * 1. Create the stats user and add it to the wheel group. This user will own the livestats installation and obtain and extract the archive. Additionally allow stats to sudo. # sudo useradd -c "LiveStats User" -G wheel -m /usr/local/livestats stats * 2. Alternately forward all the email from stats to root. o a. Add stats:root your /etc/aliases file o b. Then run # newaliases * 3. Create the directory for the stat's user home and extract the archive making sure to follow the structure outlined above. # mkdir -p /usr/local/livestats # cd /usr/local/livestats # unzip /path/to/livestats.zip * 3. Change the ownership of /usr/local/livestats and all its subdirectories to the stats user and make sure the perl scripts are executable by their owner. # chown -R stats: /usr/local/livestats # chmod +x bin/*.pl # chmod +x sbin/*.pl # chmod +x www/internal/cgi-bin/*.pl # chmod +x www/external/cgi-bin/*.pl * 4. Create a log file that will be used by the scripts and change its owner to the stats user created above. Note that the path to the log file is hard-coded in the scripts. If you decide to put the log elsewhere, you will need to update all the scripts to reflect that change. Since /var/log/ is owned by root, you will either need to be logged in as root or use sudo to execute these commands: # touch /var/log/livestats.log # chown stats: /var/log/livestats.log Softlinks and Additional Directories In order to properly function, several softlinks and additional directories must be set-up under the /usr/local/livestats/www/internal/cgi-bin subdirectories. Refer to the list below for which links need to be established The following list of PERL scripts are represented in the cgi-bin directory as softlinks to the actual scripts located in /usr/local/livestats/bin. dashboard.pl -> ../../../bin/dashboard.pl* dashboardWaterfall.pl -> ../../../bin/dashboardWaterfall.pl* makeBandwidthPerUnique.pl -> ../../../bin/makeBandwidthPerUnique.pl* makeGameStats-Month.pl -> ../../../bin/makeGameStats-Month.pl* makeGameStats.pl -> ../../../bin/makeGameStats.pl* makeGameStatsDaily.pl -> ../../../bin/makeGameStatsDaily.pl* makeMySQL.pl -> ../../../bin/makeMySQL.pl* makeMySQLgroup.pl -> ../../../bin/makeMySQLgroup.pl* makeReplicationDelay.pl -> ../../../bin/makeReplicationDelay.pl* make.pl -> ../../../bin/makeSNMP.pl* makeSNMPappCPU.pl -> ../../../bin/makeSNMPappCPU.pl* makeSNMPdbCPU.pl -> ../../../bin/makeSNMPdbCPU.pl* makeSandboxBandwidth.pl -> ../../../bin/makeSandboxBandwidth.pl* makeSandboxCPU.pl -> ../../../bin/makeSandboxCPU.pl makeSandboxCPUusage.pl -> ../../../bin/makeSandboxCPUusage.pl* makeSandboxPerfPage.pl -> ../../../bin/makeSandboxPerfPage.pl* makeSandboxPing-Month.pl -> ../../../bin/makeSandboxPing-Month.pl* makeSandboxPing-mam.pl -> ../../../bin/makeSandboxPing-mam.pl* makeSandboxPing.pl -> ../../../bin/makeSandboxPing.pl* makeSandboxProbe.pl -> ../../../bin/makeSandboxProbe.pl* makeSandboxTraffic.pl -> ../../../bin/makeSandboxTraffic.pl* makeTotalMatch.pl -> ../../../bin/makeTotalMatch.pl* makeTrafficPerSandbox-Year.pl -> ../../../bin/makeTrafficPerSandbox-Year.pl* makeTrafficPerSandbox.pl -> ../../../bin/makeTrafficPerSandbox.pl* * 1. Create the softlinks as shown below for makeReplicationDelay.pl. This must be done for every script listed above. # cd /usr/local/livestats/www/internal/cgi-bin # ln -s ../../../bin/makeReplicationDelay.pl makeReplicationDelay.pl Additional Directories The /usr/local/livestats/internal/ directory should also contain subdirectories named graphs, html, images, includes, logs and xml. If any of these directories do not exist they must be created manually. Modifying The Scripts For Your Environment Some scripts have hard-coded information inside that needs to be edited to suit the environment in which LiveStats will run. Each perl script has a set of variable definitions at the top. Here are the variables that need to be edited accordingly for each script in each of the script directories: my $datacenter = 'Canix'; # This is a name that identifies the location of your datacenter. my $dbPassword = 'D:x2=lUJbH5G'; # This password is used to access the databases and it is in almost every script. (Refer to the MySQL section) my $sbpexec = '/usr/local/livestats/sbin/SandboxProbe-R17'; # The location of the Linux based SandboxProbe executable. my $sbpuser = 'SandboxProbe'; # TBD my $sbppass = 'ocsne9dj'; # TBD my $community = 'quazalnet'; # The SNMP community name. my $canixURL = 'http://192.168.20.90/'; # This is the ip address of the LiveStats server (Put the internal IP address of the machine you are setting up LiveStats on) Required Perl Packages Some perl scripts require specific perl modules to work correctly. To achieve this we use a more up-to-date RPM repository for those and the standard repository for the other packages we will need. The following list describes which repositories should be used when getting and installing packages. The standard repository should already be available on your system by default. To add the RPMforge repository please follow this link: http://dag.wieers.com/rpm/packages/rpmforge-release/. For more information on how to install and enable RPMforge repositories take a look at the following site: http://rpmrepo.org/RPMforge. Once the RPM repositories are set up and working, proceed to install the packages in the list below. * 1. Install the following packages from the specified repository. Standard CentOS Repo: Mysql mysql-server samba-common samba-client am-util compat-libstdc++-33 perl-DBD-MySQL net-snmp-perl RPMforge Repo: perl-Net-SNMP perl-GD perl-GD-Graph perl-GD-Graph3d perl-GD-Text-Util perl-Mail-Sendmail perl-Geo-IP perl-Geo-IP-PurePerl perl-Geography-Countries sudo yum install Important Note about perl-Geo-IP: On CentOS 5.x, yum may select the CentOS version instead of the RPMForge version. You need to manually download the RPMForge version. Also,you will need to download the latest GeoLite Country Binary Format from http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz. Extract and place this file in /usr/share/GeoIP/GeoIP.dat in order to get the country codes to work properly. Install and configure Apache The Apache web server needs to be installed, and the LiveStats configuration added to it. The archive contains two .conf files for use with Apache. For this installation, we will use the one named livestats_internal.conf. Copy this file from the livestats/setup directory into the Apache conf.d directory. Alternatively, you can add the contents of this file to your httpd.conf file and restart Apache. Make sure to edit your mime types to allow server-side includes or none of the cgi-scripts will work. * 1. Edit /etc/httpd/httpd.conf and make sure the following are uncommented. AddType text/html .shtml AddOutputFilter INCLUDES .shtml * 2. Start the server. /etc/init.d/httpd start Troubleshooting Apache Issues If you are having problems starting Apache there are a few things you can do to try and pinpoint the problem. * 1. If there is something wrong with your Apache, but you have no idea how to figure out what's wrong, your first clues will be in the log files. There are a few log files around. All of them are located inside /var/log/apache2/. Not all of the following log files will be on your system: this depends on what modules you have enabled. * 2. If you installed a module and its not working (i.e. SSI) check if it is loaded with the following command: # httpd -D DUMP_MODULES Loaded Modules: core_module (static) mpm_prefork_module (static) http_module (static) so_module (static) auth_basic_module (shared) auth_digest_module (shared) authn_file_module (shared) authn_alias_module (shared) authn_anon_module (shared) authn_dbm_module (shared) authn_default_module (shared) authz_host_module (shared) authz_user_module (shared) authz_owner_module (shared) authz_groupfile_module (shared) authz_dbm_module (shared) authz_default_module (shared) ldap_module (shared) authnz_ldap_module (shared) include_module (shared) log_config_module (shared) logio_module (shared) env_module (shared) ext_filter_module (shared) mime_magic_module (shared) expires_module (shared) deflate_module (shared) headers_module (shared) usertrack_module (shared) setenvif_module (shared) mime_module (shared) dav_module (shared) status_module (shared) autoindex_module (shared) info_module (shared) dav_fs_module (shared) vhost_alias_module (shared) negotiation_module (shared) dir_module (shared) actions_module (shared) speling_module (shared) userdir_module (shared) alias_module (shared) rewrite_module (shared) proxy_module (shared) proxy_balancer_module (shared) proxy_ftp_module (shared) proxy_http_module (shared) proxy_connect_module (shared) cache_module (shared) suexec_module (shared) disk_cache_module (shared) file_cache_module (shared) mem_cache_module (shared) cgi_module (shared) version_module (shared) proxy_ajp_module (shared) ssl_module (shared) Syntax OK * 3. Verify that the virtual hosts syntax is correct with the following command (The output is an example output your results may vary): # httpd -S VirtualHost configuration: wildcard NameVirtualHosts and _default_ servers: *:443 livestats.quazal.net (/etc/httpd/conf.d/livestats_external.conf:7) *:80 is a NameVirtualHost default server livestats.quazalnet.local (/etc/httpd/conf.d/livestats_internal.conf:7) port 80 namevhost livestats.quazalnet.local (/etc/httpd/conf.d/livestats.conf:7) Syntax OK * 4. Make sure the permissions are correct and that Apache/httpd can read the files under /usr/local/livestats/www/.The simplest way to do this is to su - apache and try to read the directories as that user (make sure to use the username that Apache/httpd runs as). If you can't then Apache can't either, fix the permissions and try again. * 5. Apache sometimes appears to return the CGI code instead of running those scripts and returning the script output. If this happens even though the module is enabled in /etc/httpd/conf.d/ it's very likely to be a cache issue. Clearing the webbrowser cache fixes this browser side issue. With firefox you can use Right-Click, hold down SHIFT and click Reload. Sometimes this problem can also be seen only when accessing the webserver using it's DNS name but not when accessing the webserver using its IP address. This is a strong indication that it's a cache issue. This problem can also be fixed by clearing the web browser cache. * 6. If you have a security system installed on your Linux server make sure you configure it for Apache (ports 80 and 443 need to be open). Examples of this are iptables or tcp_wrappers etc. If you installed SELinux (Not recommended) then you need to configure it properly to allow Apache, confoguring SElinux is beyond the scope of this document however a good article on how to do this can be found at http://beginlinux.com/server_training/web-server/976-apache-and-selinux Install and configure MySQL LiveStats is dependent on a MySQL database that must be installed and configured.. Note that the host, port number, username and password to access the database are hard-coded in the header of every Perl script in Livestats. If you choose not to use those present there, you will need to update the scripts to reflect your changes. Livestats can also be configured to run on a duo of master/slave instances of MySQL. The insert scripts are very resource intensive and can bog down an instance. It is possible to set the insert scripts to execute on the master instance and have the make scripts (which look up data) on the read-only slave. For the purpose of this install, however, we will assume that only one server is going to be used. You will need to install MySQL 5.0 or above. The standard RPM is recommended. 1. Start the mysql server. # /etc/init.d/mysqld start 2. Login to the MySQL server using the MySQL client and change the root password. Then create a user named stats, a database named livestats. Then grant the stats user the proper rights. Pay close attention here because the password that we use here reflects the password that is hard-coded in all the scripts. The root password can be anything, but the stats user password has to be "D:x2=lUJbH5G" without the quotes. # mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 19597 Server version: 5.0.84-log Gentoo Linux mysql-5.0.84-r1 Type 'help;' or '\h' for help. Type '\c' to clear the current input statement. mysql> SET PASSWORD FOR root@localhost=PASSWORD('quazalrocks'); Query OK, 0 rows affected (0.00 sec) mysql> CREATE DATABASE livestats; Query OK, 0 rows affected (0.00 sec) mysql> GRANT SELECT, INSERT ON livestats.* TO stats IDENTIFIED BY "D:x2=lUJbH5G"; Query OK, 0 rows affected (0.00 sec) mysql> FLUSH PRIVILEGES; Query OK, 0 rows affected (0.00 sec) * 2. To create all required tables you can use the .sql script provided with the archive, for example within mysql you would type the following: mysql> source $FULLPATH/base_tables.sql * 3. Run the scripts found under livestats/database to create all the tables except for the individual ,  and tables, which will have to be created manually for each server and game tracked. Configure Crontabs and Activate Data Collection You will need to fill in the appropriate information in the gameindex table and sandboxindex tables. When adding new entries, you must set the isActive field to N, if not, the graph creation scripts will throw errors since no data is available. To activate data collection, you need to add an entry in the stats user's CRON. The last two parameters are the sleep_time (X) and the sandbox node name. Note however that it is OK to leave isActive to Y but you will get some errors. Note that the X below refers to a random number in seconds. Use any random number between 5 and 30 making sure that no two intervals are the same. * 1. Edit the stats user crontab to add the cron entries required to execute the scripts at timed intervals. # su - stats Password: # crontab -e * 2. To collect MySQL & Sandbox GameStats information, you must create a user in each MySQL instance in order for the MySQL performance metrics and the GameStats for each sandbox to be retrieved.Place the user's password inside the single quotes: GRANT SELECT, REPLICATION CLIENT ON *.* TO stats IDENTIFIED BY ''; * 3. It is recommended to copy paste the following and keep the comments as reference. Replace where appropriate. # SandBox Data Collection 1-59/5 * * * * /usr/local/livestats/bin/insertSandboxProbe.pl X 2-59/5 * * * * /usr/local/livestats/bin/insertSandboxProbePing.pl X # Game Stats Data Collection # To activate the GameStats data collection, you need to add an entry in the stats user's CRON. The last two parameters are the Sandbox Name and a Y or N. Meaning isActive Yes or No. # This tells us if the table is active and contains data for us to get. 0 6 * * * /usr/local/livestats/bin/insertGameStats.pl  Y 4-59/5 * * * * /usr/local/livestats/bin/insertGameStats.pl  N 0 6 * * * /usr/local/livestats/bin/insertGameStats.pl  Y 4-59/5 * * * * /usr/local/livestats/bin/insertGameStats.pl N # MySQL Data Collection # To activate the MySQL data collection, you need to add an entry in the stats user's CRON. The last two parameters are the hostname of the DB server (ldbXX ) and the MySQL Port. 3-59/5 * * * * /usr/local/livestats/bin/insertMySQL.pl ldbXX 3306 # MySQLReplication Data Collection (Optional) # To activate the MySQLReplication Delay data collection, you need to add an entry in the stats user's CRON. # This is only necessary if you have installed a master/slave database setup for Livestats as previously mentioned. 3-59/5 * * * * /usr/local/livestats/bin/insertMySQLReplication.pl # SNMP Data Collection # To collect SNMP information, you will need to configure each Windows and Linux servers' respective SNMP service to allow connection from the LiveStats server. # The community the scripts use is named quazalnet this can be changed to whatever you like but some scripts rely on it to funtion properly. # To activate the SNMP data collection, you need to add an entry in the stats user's CRON. The only parameter is the hostname of the server. 3-59/5 * * * * /usr/local/livestats/bin/insertSNMP.pl Setting up Rendez-Vous Log Access In order to set up the logs, you will need to install samba client files. Installing the entire samba suite is OK since it will install the mount utilities that we need. You need to also install the automounter package (am-utils). Once everything is installed, you need to create a password file in /root/.smbpasswd with the following lines: username=qadmin password=somepassword The username is not important. Feel free to use whatever you like but it has to have rights to view/mount windows directories from the Sandbox server using smbclient. Specifically, the RV folder that is shared from the LiveStats server. Edit the /etc/auto.misc file to contain a line similar to the following for each sandbox server you want to monitor: ls01 -fstype=cifs,rw,noperm,credentials=/root/.smbpasswd ://192.168.xx.xx/RV Save and close the file and start the automount service: /etc/init.d/autofs start At this point the Livestats system will be able to run the script that reads the log files and links them on the main web page. Rendez-Vous Server Install Install Perl In order to run the resource perl script on windows we need perl. It is recommended to download and install the latest version of Perl from Activestate: http://www.activestate.com/activeperl/ * Install perl in D:\tools\perl because the script excpects it to be in that location. * There are no additional modules required for perl to run this script on windows. Setting up SNMP on a Windows Server The setup for Windows Server requires the snmp package to be installed. The steps below outline the process of adding and configuring SNMPD on Windows Server: Click Control-Panel -> Add/Remove Programs Click on Add/Remove Windows Components. The Components Wizard window will appear. Select Management and Monitoring Tools and click on the Details button. Put a checkmark on Simple Network Management Protocol Click OK, then click Next/Finish on the Components Wizard To configure SNMP on Windows server you will need to go to the services and set it up from there. Click on Start -> Run, type "services.msc" and click OK. Find SNMP Service in the list of services, right-click on it and select properties. Click on the Security tab and click the "Add" button. Select READ ONLY and type in the community name, in our case 'quazalnet' and click "Add" In the bottom section click the "Accept SNMP packets from these hosts" radio button and add the IP address of your livestats server. (The above step is optional but recommended for security.) Once you're done click OK, go to the General tab, set the service to Automatic and start it. To test that it is working properly you can use the snmpwalk utility, preferably from your livestats linux server: # snmpwalk -v 1 -c quazalnet ServerName.MyDomain Pycron Setup In order to gather system data for our LS servers we need to install pycron and run a cron from the Windows servers. The installer is located in the livestats.zip package under the sbin directory. Copy the installer to your LS server and install it. * 1. Configuring Pycron is fairly straight forward: Click on Start -> All Programs -> Pycron -> crontab.txt Editor * 2. Add a new task using the following parameters. The directories assume you installedRendez-Vous in D:, change that if it is not appropriate. Command: D:\Tools\Perl\bin\perl.exe Parameters: D:\Tools\livestats\ressourcesPerSandbox.pl Minute: 0,5,10,15,20,25,30,35,40,45,50,55 * 3. Put an '*' in all the other fields and click OK. This script will run every 5 minutes and collect the stats needed for livestats. Shared Rendez-Vous Drive The RV folder needs to be shared for the automount user on the livestats sever. 1. Control click (right-click) the RV folder 2. From the dropdown menu select Properties 3. In the Properties window select the Sharing tab. 4. Select Share this folder 5. Set the Share Name to RV 6. Set the permissions for the sutomount user to read the shared drive. (The default is for everyone to be able to read the shared drive) 7. Select Ok Firewall Server Install Configure the filrewall rules The trafficPerSandbox.pl needs to be placed on the firewall. This is a data collection script for the Traffic section. It will query the iptables chains on the firewall and store the data in a table called trafficdata. SQL query to create a blank trafficdata table: CREATE TABLE `trafficdata` ( `acquisition` date NOT NULL, `gameid` smallint(5) unsigned NOT NULL, `firewall` enum('fw1','fw2','fw3','fw4') NOT NULL, `type` enum('auth','regular','xmlrpc','lsp') NOT NULL, `inbound` bigint(20) unsigned NOT NULL, `outbound` bigint(20) unsigned NOT NULL, KEY `date_gameid` (`acquisition`,`gameid`) ); When it runs it parses the iptables rules and it collects data from the packet counters for RV and XMLRPC ports and then inserts them into the livestats database. Once its complete it resets the counter to zero so keep in mind that the script is destructive. The line below taken from the script shows what it parses: my %iptablesChains = ('inbound' => ['LIVE_IN','XMLRPC_LIVE_IN','LSP_PVT_LIVE_IN'], 'outbound' => ['LIVE_OUT','XMLRPC_LIVE_OUT','LSP_PVT_LIVE_OUT']); A typical parse looks like this: [root@fw1 ~]# iptables -nvL LIVE_IN Chain LIVE_IN (4 references) pkts bytes target prot opt in out source destination 73792 3569K ACCEPT udp -- * * 0.0.0.0/0 0.0.0.0/0 udp dpt:30930 2731K 111M ACCEPT udp -- * * 0.0.0.0/0 0.0.0.0/0 udp dpt:30931 The chain OUTPUT on the firewall needs to allow traffic to the livestats database. If you are running iptables on the livestats server make sure to also allow it to accept traffic from the firewall and to the database if on a different machine. Configure the cronjobs to collect data The firewall must be running iptables for this to work properly. The script needs to be placed in the root home folder and a cron must be added to run it once a day at midnight as shown below: 0 0 * * * /root/scripts/trafficPerSandbox.pl Maintenance Adding Games To LiveStats Adding a New Database Server Now that our initial setup is complete we can easily add new elements to our LiveStats setup. These new elements can be either a new server, a new database, a new sandbox and new sandboxes. The following instructions will outline the step by step instructions on how to add new elements. * 1. The serverindex table contains information associated with the server specifications. For each server (database or RendezVous), one entry must be created in this table. Connect to the master DB and add the new server in this table: INSERT INTO serverindex (svrid,isActive,type,shortDesc,datacenter,publicIP,longDesc,nbOfCPUs,nbOfCores,MemoryInKB) values('value1','value2','value3', etc); * 2. The databaseindex table contains information associated with the database specifications. For each database server, one entry must be created in this table: INSERT INTO databaseindex (dbid,isActive,svrid,port,isSlave,version) values('value1','value2','value3', etc); * 3. The ldbxx_yyyymysql table contains the information concerning the performance of a MySQL database server instance. The format of the table name is ldb_mysql. For each database server, one ldbxxmysql table must be created, where is the server name. CREATE TABLE `ldbXX_3306mysql` ( `acquisition` datetime NOT NULL, `mysqlid` tinyint(3) unsigned NOT NULL, `rawvalue` bigint(20) unsigned NOT NULL, `value` int(10) unsigned default NULL, KEY `date_id` (`acquisition`,`mysqlid`) ) ENGINE=MyISAM DEFAULT CHARSET=latin1 * 4. The ldbxxsnmp table contains the information related to the performance of a database server. The data is collected via SNMP calls. For each database server, one ldbxxsnmp table must be created, where is the server name. CREATE TABLE `ldbXXsnmp` ( `acquisition` datetime NOT NULL, `snmpid` tinyint(3) unsigned NOT NULL, `rawvalue` bigint(20) unsigned NOT NULL, `value` int(10) unsigned default NULL, KEY `date_id` (`acquisition`,`snmpid`) ); Note: If the new server is a slave, add it to the dbtableindex table. Adding a Game Title to Livestats A game title can have various SKU (PS3, X360, Wii etc.). A SKU is what we typically call a sandbox in Quazal terminology. The following instructions will outline the steps required to add a new game to monitor. Steps 4 to 7 are the steps required to setup the external access. * 1. Connect to the master DB and add the description of the new game in the gametitleindex table. The name “Split Second” is shown as an example, replace it with the actual name of your game. The httpdir field is the directory that will be created for the client side (SSL) section of LiveStats. INSERT INTO gametitleindex SET gametitle='Split Second', httpdir="splitsecond"; * 2. Once this is done we must retrieve the game’s titleID from the table. Note this number because we will need it for the next step. SELECT titleID FROM gametitleindex where gametitle='Split Second'; * 3. Add the new game title to the clientindex table, username is the customer’s username in the htaccess file (SSL side) and titleID is the game title that we retrieved in the previous step. This command will prepare the client web page for external access (SSL). Another way to get the username is through SandboxManager. Look at the "OsUser" attribute of the Sandbox instance. INSERT INTO clientindex values ('username',titleID,'1,2,3,4,5,6,7,8,13,14,15,16,21,22,23,26,27,28,29,30'); * 4. In gametitleindex make sure the "httpdir" has been filled. * 5. On the slave server, the other soft links found in the graphs, logs and xml directory can be created by running the buildClientHTML.pl script. * 6. The customer username and password are handled by Apache's authentication mechanism. The customer directory has its own ".htaccess" file which is created by buildClientHTML.pl script. The ".htpasswds" is located in /etc/httpd/conf. If it does not exist it should be created. * Then add the customer password as root with (On the slave livestats server if it exists): htpasswd -s /etc/httpd/conf/.htpasswds Adding a Sandbox to Livestats A sandbox is cluster with various nodes spread over the live servers. In the gameindex table, we will add an entry describing the new game instance. It will point to the new game title in the gamegitleindex table and the databases in databaseindex that it uses. For each new game instance, you will need also need to add the four new tables to the Livestats master database. These tables will hold the ping, sandboxprobe and index data. The gamenameindex table will contain the type of probes performed on the game. The gamenameping table will contain the ping results. The gamenamesbp table will contain the result of the SandboxProbes. The gamenamestats table will contain the RendezVous metrics extracted by the Livestats system. * 1. Connect to the master DB and query for the game titleID. Yes this is the same step as above so if you noted down the number you can skip this step. SELECT titleID FROM gametitleindex where gametitle='Split Second'; * 2. Once we have the titleId we need to insert it in the gameindex table. The gameindex table contains the information for each hosted game. If you did not setup a slave DB you can leave the dbiBackup feld empty. To get the dbidMaster ID look for it in the databaseindex table. INSERT INTO gameindex SET titleid=51, Shortdesc='splitsecpclive', Longdesc='Split Second (PC)', isActive='Y', startDate='20100310', accesskey='3wyEgW4x', encrypt='Y', gameStatsIds='5,26,1,17,12,20,23,13,6,7,10,11,14,15,16', dbidMaster=17, dbidBackup=18; * 3. In the sandboxindex table, we need to add an entry describing the new node (SandBox Node). It will point to the new game in the gameindex table and a physical server in the serverindex table where it is hosted. Use 1_authreg for a regular node and 3_comp for a master node. The gameid field is the game ID or sandbox ID svrid is the live server id (SELECT * FROM serverindex WHERE type ="ls";) and type is an enum('0_auth','1_authreg','2_reg','3_comp') INSERT INTO sandboxindex SET idname='rb2wiilive1', svrid=53, port='30264', isActive='Y', gameid=19, type='2_reg'; * 4. Add the four new tables as show below, replace “splitsecpclive” with the actual name of the game you are adding. CREATE TABLE `splitsecpclive` ( `sbpid` smallint(5) unsigned NOT NULL auto_increment, `probetype` varchar(255) NOT NULL default '', PRIMARY KEY (`sbpid`), UNIQUE KEY `probetype` (`probetype`) ); CREATE TABLE `splitsecpclivesbp` ( `acquisition` datetime NOT NULL, `sbnid` smallint(5) unsigned NOT NULL, `sbpid` smallint(5) unsigned NOT NULL, `minimum` int(10) unsigned NOT NULL, `maximum` int(10) unsigned NOT NULL, `average` int(10) unsigned NOT NULL, `total` bigint(20) unsigned NOT NULL default '0', `current` bigint(20) unsigned NOT NULL, KEY `date_id` (`acquisition`,`sbpid`) ); CREATE TABLE `splitsecpcliveping` ( `acquisition` datetime NOT NULL, `sbnid` smallint(5) unsigned NOT NULL, `ping1` smallint(5) unsigned NOT NULL, `ping2` smallint(5) unsigned NOT NULL, `ping3` smallint(5) unsigned NOT NULL, `ping4` smallint(5) unsigned NOT NULL, KEY `acquisition` (`acquisition`) ); CREATE TABLE `splitsecpclivestats` ( `acquisition` datetime NOT NULL, `gsid` smallint(5) unsigned NOT NULL, `gsvalue` int(10) unsigned NOT NULL, KEY `gsid` (`gsid`) ); Adding a New Cron Entry Once you have filled in the appropriate information in the gameindex table and sandboxindex tables, you will have to activate the data collection by adding entries in the stats user's CRON. * 1. Log on as the stats user and edit the crontab as shown. # su - stats # crontab -e * 2. Copy and paste the following into the crontab and edit it accordingly. Leave the comments in there for future reference ;-) # The sleep_time parameter is a random number in seconds from 5 to 30. # This can be anything but it is recommended that the number is different for each script in order to avoid potential conflicts. # When adding new entries it is also recommended to set the isActive field to N in the master DB. # If it is set to Y the scripts will throw errors since no data is available. 1-59/5 * * * * /usr/local/livestats/bin/insertSandboxProbe.pl X 2-59/5 * * * * /usr/local/livestats/bin/insertSandboxProbePing.pl X 4-59/5 * * * * /usr/local/livestats/bin/insertGameStats.pl  N 0 6 * * * /usr/local/livestats/bin/insertGameStats.pl Y Note: It is OK to leave this as Y if you don’t mind errors for the first 30 minutes. Please allow the cron to run for at least 6 hours in order to collect all the data it needs. As the data populates there will be less and less errors reported. If the main page is empty you will probably need to run all the make* scripts by hand at least once. You also should run the buildHTML.pl script by hand in order to create the external client access page. Configuring the Rendez-Vous EventStats Package for LiveStats The EventStats table can contain statistical information on node events as well as 2 to 3 rows per connection (one for login, another one for logout and maybe a third to mark a restart). A "cleanup script", dump_connection_stats.py, is provided to process the raw connection events in the EventStats table and turn them into coherent concise statistics (for LiveStats) about player activity in a (ConnectionStats) target table. This stand-alone script can be called from the command line or by a cron job on almost any machine that can connect to the database to periodically process events. ConnectionStats Table The ConnectionStats table is defined as follows: Field Type Default Description did tinyint, not NULL 0 The ID of the daemon process to which this event is made. cid int, not NULL 0 The ConnectionID of the initiator of the event. pid int, not NULL 0 The PrincipalID of the initiator of the event. logindate Datetime not NULL '0000-00-00 00:00:00' The login date and time of the Connection. logoutdate Datetime NULL The logout date and time for the corresponding DaemonID/ConnectionID. This could also be the server restart date if the serverrestart flag is 1. serverrestart tinyint, not NULL 0 If this flag is set to 1, it indicates that the user was logged in when the server went down. publicip int, NULL 0 The Principal's IP address. * If the EventStats table contains more than one logout row for a cid, dump_connection_stats will use the row with the smallest timestamp. * If the user logs in and out quickly, you may only see the recorded login in the target table after a first pass of dump_connection_stats. But the script is capable of recognizing orphan entries and can add the logout on the next pass. * Similarly, if the node fails, the node event is recorded in the EventStats table and dump_connection_stats will be able to update the target table entry when the node restarts. * The dump_connection_stats script: o retrieves data from the raw EventStats table and inserts or updates the data in the ConnectionStats table. Any failure to do so, and the failed query is written to a text file located in the script's working directory (the default file name is dcs_errors.txt). o reads a maximum of 1000 records at a time to prevent system slowdowns. o empties the EventStats table before exiting. Modifying the ConnectionStats Table 1. The default schema for the ConnectionStats table after an initial Rendez-Vous installation is incorrect. You will need to drop the table and replace it with the following schema: CREATE TABLE `connectionstats` ( `did` int(10) unsigned NOT NULL default '0', `cid` int(10) unsigned NOT NULL default '0', `pid` int(10) unsigned NOT NULL default '0', `logindate` datetime NOT NULL, `logoutdate` datetime default NULL, `serverrestart` tinyint(1) NOT NULL default '0', `publicip` int(10) unsigned default '0', `version1` int(11) default NULL, KEY `did_cid` (`did`,`cid`), KEY `i_did_logindate_logoutdate` (`did`,`logindate`,`logoutdate`), KEY `logindate` (`logindate`), KEY `logoutdate` (`logoutdate`) ); Customizing EventStats If you wish to change the default EventStats settings (location and name of the database where it is stored) you must In Rendez-Vous * 1. Make a copy of the sample configuration file, config_sample.py and copy it to the Rerndez-Vous ..\Scripts\Admin}} or the {{{..\Scripts\Users directory (which are "safe" from updates but still in the path). * 2. Modify the configuration settings to contain the access parameters for your EventStats table. * 3. In the Rendez-Vous Site/User configuration file, import the EventStats package (for the script) along with your customized EventStats configuration file (, for example): import EventStats import event_stats_config * 4. Use the EventStats.configure() method to set the new configuration. EventStats.GetInstance().configure(event_stats_config.credentials()) Once this is done, the EventStats package will use the access parameters in the new config file to create and write them to the  table. Note that if the table doesn't exist, the package will create it. On the Database Server A "cleanup script", dump_connection_stats.py, is provided to process the raw connection events in the table, turn them into coherent concise statistics about player activity and insert them in a target connection stats table. To use the dump script, you must either create a configuration file for the ConnectionStats table containing the table's access parameters or add a second credentials class to the original EventStats configuration file. Even if you don't want to change the default configuration for the package, you will have to enter your default Rendez-Vous settings so that the stand-alone dump script can find the  and  tables. Create a Configuration file for the Dump Script * 1. Copy dump_connection_stats.py and the EventStats configuration file ( created above) to wherever you will run the script. The contents of the configuration script must reflect the EventStats configuration or the dump script will not know where to find it or how to log on to the database containing the EventStats table. * 2. Create a second configuration file () containing the access parameters to the ConnectionStats table including its name. Or add a second credentials class to the EventStats configuration file (combined_config.py). The format of the combined file is as follows: #combined_config.py class e_credentials: # First credentials class for the event stats table table='EventStats' # The EventStats or target table name. This must be a class variable. def __init__(self): self.host='host_address' # The host name of the server on which the table's database can be found. self.port='host_port' # The port on the host through which the table's database can be accessed. self.user='user_name' # The user name that the EventStats package uses to log in to the database host. self.passwd='user_password' # The password for the user ID. self.db='database_name' # The name of the database where the table is created/can be found. class c_credentials: # Second credentials class for the connection stats table table='ConnectionStats' # The ConnectionStats or target table name. This must be a class variable. def __init__(self): self.host='host_address' # The host name of the server on which the table's database can be found. self.port='host_port' # The port on the host through which the table's database can be accessed. self.user='user_name' # The user name that the EventStats package uses to log in to the database host. self.passwd='user_password' # The password for the user ID. self.db='database_name' # The name of the database where the table is created/can be found. * Note: the EventStats and ConnectionStats credentials classes must be named e_credentials and c_credentials respectively. Note also that if the ConnectionStats target table does not exist, the dump script will create one. Using the Dump Script * 1. You can use the dump script as a standalone script from the command line but for LiveStats it is advisable to set it up as a cron job on the local or a remote server. The command line parameters change depending on whether you are using one or two configuration files: dump_connection_stats.py -e  -c  [-x ] dump_connection_stats.py -i  [-x ] * where o eventstats_config.py and connstats_config.py or combined_config.py are the configuration files for the EventStats and ConnectionStats tables and o query_error_file is a text file containing any processing failures. The default is dcs_errors.txt in the current working directory. * To run this script, the MySQLdb (python interface) must be installed and both it and the configuration script(s) must be in the command line's path. * Note: o If the dump_connection_stats script fails to process any entries from the raw Event Stats table, it will log the failed query to an errors text file. o The dump_connection_stats script prints information or warning messages to stdout. Any serious error encountered is printed to stderr. o If dump_connection_stats is interrupted during processing, partially processed Event Stats data will be left behind in temporary tables. The next time dump_connection_stats runs, it will attempt recovery of that data by processing it a second time. Activating the EventStats Script To activate the EventStats script on the database server, 1. Copy the configuration files created above to the server's /root/eventstats directory. 2. Add the dumpscript command line shown above to the /root/eventstats/eventstats.sh Reference * Hosting/Hardware/Networking#TrafficFlow for a description of the LiveStats traffic flow. * Hosting/Hardware/Networking for complete LiveStats installation and maintenance instructions. LiveStats Directories * LiveStats/BIN Directory * LiveStats/SBIN Directory * LiveStats/TEMPLATES Directory * LiveStats/Internal LiveStats Directories * LiveStats/Database Index Tables 
